{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478d8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Build Supabase engine\n",
    "DATABASE_DSN = (\n",
    "    \"postgresql://postgres.avcznjglmqhmzqtsrlfg:Czheyuan0227@\"\n",
    "    \"aws-0-us-east-2.pooler.supabase.com:6543/postgres?sslmode=require\"\n",
    ")\n",
    "engine = create_engine(DATABASE_DSN, pool_pre_ping=True)\n",
    "\n",
    "#SO \n",
    "#Backordered是指目前SO尚未出貨的數量，如果用QTY的話會包含已經partial出貨的\n",
    "# SO = pd.read_csv(\"Data/open sales orders.csv\", encoding=\"utf-8\", encoding_errors=\"ignore\")\n",
    "SO = pd.read_sql_table(\"open_sales_orders\", con=engine, schema=\"public\") # Pull from Supabase\n",
    "SO = SO.drop(columns=[\"Qty\"], axis =1)\n",
    "SO.rename(columns={\"Date\":\"Order Date\",\"Num\":\"QB Num\",\"Backordered\":\"Qty(-)\"},inplace=True)\n",
    "SO = SO.drop(SO.columns[[0]], axis =1)\n",
    "SO = SO.drop(columns=['Type','Due Date','Terms','Amount','Deliv Date','Open Balance',\"Invoiced\",\"Rep\"], axis =1)\n",
    "SO = SO.dropna(axis=0, how='all',subset=None, inplace=False)\n",
    "SO = SO.dropna(thresh=6)\n",
    "SO['Item']= SO['Item'].str.split(':',expand=True)[1]\n",
    "SO['Item']= SO['Item'].str.replace(\"*\",\"\")\n",
    "SO['Qty(+)']=\"0\"\n",
    "SO['Remark']=\"\"\n",
    "SO['Order Date']= pd.to_datetime(SO['Order Date'])\n",
    "SO['Order Date'] = SO['Order Date'].dt.strftime('%Y/%m/%d')\n",
    "SO['Ship Date']= pd.to_datetime(SO['Ship Date'])\n",
    "SO['Ship Date'] = SO['Ship Date'].dt.strftime('%Y/%m/%d')\n",
    "columns = ['Order Date','Ship Date', 'QB Num',\"P. O. #\",\"Name\",'Qty(+)','Qty(-)', 'Item','Inventory Site','Remark']\n",
    "\n",
    "#\"POD\"\n",
    "pod = pd.read_csv(\"open purchase orders.csv\", encoding=\"ISO-8859-1\")\n",
    "pod = pod.drop(columns=['Name','Amount','Open Balance',\"Rcv'd\",\"Qty\"], axis =1)\n",
    "pod.rename(columns={\"Date\":\"Order Date\",\"Num\":\"QB Num\",\"Source Name\":\"Name\",\"Backordered\":\"Qty(+)\"},inplace=True)\n",
    "pod = pod.drop(pod.columns[[0]], axis =1)\n",
    "pod = pod.dropna(axis=0, how='all',subset=None, inplace=False)\n",
    "pod = pod.dropna(thresh=5)\n",
    "pod['Memo'] = pod['Memo'].str.split(' ',expand=True)[0]\n",
    "pod['QB Num'] = pod['QB Num'].str.split('(',expand=True)[0]\n",
    "# print(pod['Memo'].str.split('*',expand=True)[0])\n",
    "pod['Memo'] = pod['Memo'].str.replace(\"*\",\"\")\n",
    "pod.rename(columns={\"Memo\":\"Item\"},inplace=True)\n",
    "pod['Order Date']= pd.to_datetime(pod['Order Date'])\n",
    "pod['Deliv Date']= pd.to_datetime(pod['Deliv Date'])\n",
    "pod['Order Date'] = pod['Order Date'].dt.strftime('%Y/%m/%d')\n",
    "pod['Deliv Date'] = pod['Deliv Date'].dt.strftime('%Y/%m/%d')\n",
    "pod.to_csv('open purchase2.csv',index=False)\n",
    "\n",
    "\n",
    "#\"NAV\"\n",
    "NAV = pd.read_csv(\"Sales Date return platform.csv\", usecols=['Document No.', \"Customer PO No.\", \"Customer Ordering Model\",\n",
    "                                                             \"OP Estimated Shipping Date\", \"Quantity\", \"No.\",\n",
    "                                                             \"Customer Ordering Desc.\"], encoding='utf-8')\n",
    "NAV.rename(columns={\"Customer PO No.\": \"QB Num\", \"Customer Ordering Model\": \"Item\", 'Document No.': \"Remark\",\n",
    "                    \"OP Estimated Shipping Date\": \"Ship Date\", \"Quantity\": \"Qty(+)\"}, inplace=True)\n",
    "NAV = NAV[NAV['Item'] != 'Engineer Service- COS']\n",
    "NAV = NAV[NAV['Item'] != 'CUSTOMER SERVICES']\n",
    "NAV = NAV[NAV['Item'] != 'FORWARDING CHARGE, EXCLUDING IMPORT DUTY.']\n",
    "# print(NAV['QB Num'])\n",
    "NAV['QB Num'] = NAV['QB Num'].str.split('(').str[0]\n",
    "\n",
    "NAV.to_csv('NAV1.csv', index=False)\n",
    "\n",
    " \n",
    "#Inventory\n",
    "INV = pd.read_sql_table(\"inventory_status\", con=engine, schema=\"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeec6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Remark      QB Num               No.  \\\n",
      "3    SO25050035  POD-250648  S51-SL1708FF-003   \n",
      "3    SO25050035  POD-250648  S51-SL1708FF-003   \n",
      "3    SO25050035  POD-250648  S51-SL1708FF-003   \n",
      "10   SO25050036  POD-250649  S51-SL1708FF-003   \n",
      "10   SO25050036  POD-250649  S51-SL1708FF-003   \n",
      "..          ...         ...               ...   \n",
      "436  SO25100096  POD-251415  S50-EC500630-PUB   \n",
      "437  SO25100096  POD-251415  S60-XC803400-027   \n",
      "437  SO25100096  POD-251415  S60-XC803400-027   \n",
      "437  SO25100096  POD-251415  S60-XC803400-027   \n",
      "437  SO25100096  POD-251415  S60-XC803400-027   \n",
      "\n",
      "                                               Item Qty(+)   Ship Date  \\\n",
      "3                                         i7-9700TE   10.0  2025/11/19   \n",
      "3    DDR4-16GB-32-SMandM.280-SSD-1TB-PCIe44-TLC5-PN   10.0  2025/11/19   \n",
      "3                                     SEMIL-1708-FF   10.0  2025/11/19   \n",
      "10                                        i7-9700TE   10.0  2025/12/17   \n",
      "10   DDR4-16GB-32-SMandM.280-SSD-1TB-PCIe44-TLC5-PN   10.0  2025/12/17   \n",
      "..                                              ...    ...         ...   \n",
      "436                                     Nuvo-5006LP    1.0         NaN   \n",
      "437                                        i7-9700E    3.0         NaN   \n",
      "437                               Cbl-W6F-W6F-16CM1    3.0         NaN   \n",
      "437                               Cbl-W6F-W8F-16CM1    3.0         NaN   \n",
      "437                                       Nuvo-8034    3.0         NaN   \n",
      "\n",
      "                              Customer Ordering Desc.  \n",
      "3                                           i7-9700TE  \n",
      "3    DDR4-16GB-32-SM and M.280-SSD-1TB-PCIe44-TLC5-PN  \n",
      "3                                       SEMIL-1708-FF  \n",
      "10                                          i7-9700TE  \n",
      "10   DDR4-16GB-32-SM and M.280-SSD-1TB-PCIe44-TLC5-PN  \n",
      "..                                                ...  \n",
      "436                                       Nuvo-5006LP  \n",
      "437                                          i7-9700E  \n",
      "437                                 Cbl-W6F-W6F-16CM1  \n",
      "437                                 Cbl-W6F-W8F-16CM1  \n",
      "437                                         Nuvo-8034  \n",
      "\n",
      "[262 rows x 7 columns]\n",
      "262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_18044\\1610363184.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  product_str = original_list[-1]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_18044\\1610363184.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  transformed_list['Qty(+)'] = str(quantity * float(transformed_list[4]))  # 更新數量\n"
     ]
    }
   ],
   "source": [
    "# 讀取 NAV1 並篩選符合條件的數據\n",
    "s50 = []\n",
    "\n",
    "for _, row in NAV.iterrows():\n",
    "    if row['No.'].startswith(\"S\"):  # 檢查 Item 是否以 \"S\" 開頭\n",
    "        s50.append(row)\n",
    "\n",
    "result_lists = []\n",
    "for original_list in s50:\n",
    "    # 分割字串\n",
    "    product_str = original_list[-1]\n",
    "    product_str = product_str.replace('\\u00A0', ' ').replace('\\u3000', ' ')\n",
    "    product_info = product_str.split(', including ')\n",
    "    #product_info = original_list[-1].split(', including ')\n",
    "    # print(product_info)\n",
    "    # product_info[0] = product_info[0].split(',')[0]  # 產品代碼\n",
    "    components = product_info[1].split(', ') if len(product_info) > 1 else []\n",
    "    # print(components)\n",
    "    \n",
    "    ## Append component to result_lists\n",
    "    # 建立各組件的新 list\n",
    "    for component in components:\n",
    "        new_list = original_list.copy()\n",
    "        new_list['Customer Ordering Desc.'] = component.strip()\n",
    "        result_lists.append(new_list)\n",
    "   \n",
    "    ## Append base to result_lists\n",
    "    # 加入產品代碼(Change Desc. to product_info[0])\n",
    "    new_list_with_product_code = original_list.copy()\n",
    "    new_list_with_product_code['Customer Ordering Desc.'] = product_info[0]\n",
    "    result_lists.append(new_list_with_product_code)\n",
    "    \n",
    "\n",
    "for i in range(0,len(result_lists)):\n",
    "    result_lists[i]['Item'] = result_lists[i]['Customer Ordering Desc.']\n",
    "\n",
    "\n",
    "# 調整數據格式\n",
    "transformed_lists = []\n",
    "for result_list in result_lists:\n",
    "    transformed_list = result_list.copy()\n",
    "    transformed_list['Item'] = transformed_list['Item'].replace(\" \", \"\")\n",
    "    \n",
    "    if len(transformed_list['Item']) > 1 and transformed_list['Item'][1] == 'x' and transformed_list['Item'][0].isdigit():\n",
    "        quantity = int(transformed_list['Item'].split('x')[0])\n",
    "        name = transformed_list['Item'].split('x')[-1]\n",
    "        transformed_list['Item'] = name\n",
    "        transformed_list['Qty(+)'] = str(quantity * float(transformed_list[4]))  # 更新數量\n",
    "\n",
    "    transformed_lists.append(transformed_list)\n",
    "\n",
    "print(pd.DataFrame(transformed_lists))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5e910cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before append: 367\n",
      "Appended: 263\n",
      "Rows after append: 630\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "\n",
    "file = 'NAV1.csv'\n",
    "rows_to_add = transformed_lists  # your list of rows\n",
    "\n",
    "with open(file, 'a+', encoding='utf-8', newline='') as f:\n",
    "    f.seek(0)                                  # move to start to read\n",
    "    before = sum(1 for _ in csv.reader(f))     # count existing rows (incl. header if any)\n",
    "\n",
    "    # go back to end to append\n",
    "    f.seek(0, os.SEEK_END)\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(rows_to_add)\n",
    "\n",
    "    after = before + len(rows_to_add)          # we know how many we appended\n",
    "    print(f\"Rows before append: {before}\")\n",
    "    print(f\"Appended: {len(rows_to_add)}\")\n",
    "    print(f\"Rows after append: {after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86c68345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAV 加上倉別和日期\n",
    "replace = pd.read_csv(\"item name replace.csv\")\n",
    "\n",
    "NAV = pd.read_csv(\"NAV1.csv\", usecols=['Remark', 'QB Num', 'Item', 'Qty(+)', 'Ship Date'], encoding='utf-8')\n",
    "replace_dict = dict(zip(replace['NAV'], replace['QB']))\n",
    "NAV['Item'] = NAV['Item'].replace(replace_dict)\n",
    "NAV.to_csv('NAV1.csv', index=False)\n",
    "\n",
    "# 讀取 open purchase2.csv 並處理數據\n",
    "a = pd.read_csv('open purchase2.csv', usecols=['QB Num', \"Order Date\", \"Inventory Site\", \"P. O. #\", \"Name\", \"Item\"])\n",
    "a.drop_duplicates(inplace=True)\n",
    "a['Qty(-)'] = \"0\"\n",
    "\n",
    "fil = set(a['Item'])\n",
    "NAV = NAV[NAV['Item'].isin(fil)]\n",
    "a = a.drop(columns=[\"Item\"])\n",
    "a.drop_duplicates(inplace=True)\n",
    "\n",
    "# 合併 NAV 和 open purchase2.csv\n",
    "Final = pd.merge(left=NAV, right=a, on=[\"QB Num\"], how=\"left\")\n",
    "columns = ['Order Date', 'Ship Date', 'QB Num', \"P. O. #\", \"Name\", 'Qty(-)', 'Qty(+)', 'Item', 'Inventory Site', 'Remark']\n",
    "Final.to_csv('Final.csv', index=False, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90088457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "\n",
    "def build_timephased_qty(\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    freq=\"D\",\n",
    "    initial_onhand_df=None,   # pass INV here\n",
    "    site_filter=\"WH01S-NTA\",  # focus on this site\n",
    "):\n",
    "    df = Final\n",
    "\n",
    "    # ---- Filter Site ----\n",
    "    df[\"Inventory Site\"] = df[\"Inventory Site\"].astype(str).str.strip()\n",
    "    if site_filter is not None:\n",
    "        df = df[df[\"Inventory Site\"] == site_filter].copy()\n",
    "\n",
    "    # clean numeric & date\n",
    "    df[\"Qty(+)\"] = pd.to_numeric(df[\"Qty(+)\"], errors=\"coerce\").fillna(0)\n",
    "    df[\"Qty(-)\"] = pd.to_numeric(df[\"Qty(-)\"], errors=\"coerce\").fillna(0)\n",
    "    df[\"Ship Date\"] = pd.to_datetime(df[\"Ship Date\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Ship Date\"])\n",
    "    df[\"Item\"] = df[\"Item\"].astype(str).str.strip()\n",
    "\n",
    "    # net movement per date\n",
    "    df[\"qty_change\"] = df[\"Qty(+)\"] - df[\"Qty(-)\"]\n",
    "    events = (df.groupby([\"Inventory Site\",\"Item\",\"Ship Date\"], as_index=False)[\"qty_change\"]\n",
    "                .sum()\n",
    "                .sort_values([\"Inventory Site\",\"Item\",\"Ship Date\"]))\n",
    "\n",
    "    # horizon\n",
    "    if start_date is None:\n",
    "        start = pd.Timestamp(\"2025-01-01\")   # or use today().date()\n",
    "    else:\n",
    "        start = pd.to_datetime(start_date).normalize()\n",
    "\n",
    "    if end_date is None:\n",
    "        end = start + timedelta(days=30)\n",
    "    else:\n",
    "        end = pd.to_datetime(end_date).normalize()\n",
    "\n",
    "    date_index = pd.date_range(start, end, freq=freq)\n",
    "\n",
    "    # all (site,item) pairs from events\n",
    "    pairs = events[[\"Inventory Site\",\"Item\"]].drop_duplicates()\n",
    "\n",
    "    # build continuous timeline\n",
    "    all_rows = []\n",
    "    for (site, item), grp in events.groupby([\"Inventory Site\",\"Item\"]):\n",
    "        s = grp.set_index(\"Ship Date\")[\"qty_change\"].reindex(date_index, fill_value=0.0)\n",
    "        out = pd.DataFrame({\n",
    "            \"Ship Date\": date_index,\n",
    "            \"Inventory Site\": site,\n",
    "            \"Item\": item,\n",
    "            \"Net Movement\": s.values\n",
    "        })\n",
    "        all_rows.append(out)\n",
    "\n",
    "    timeline = pd.concat(all_rows, ignore_index=True) if all_rows else pd.DataFrame(\n",
    "        columns=[\"Ship Date\",\"Inventory Site\",\"Item\",\"Net Movement\"]\n",
    "    )\n",
    "\n",
    "    # ----- add initial on-hand (INV) -----\n",
    "    # Case: INV has NO site -> broadcast to the chosen site\n",
    "    if initial_onhand_df is not None and not initial_onhand_df.empty:\n",
    "        onhand = initial_onhand_df.copy()\n",
    "        # normalize columns from INV\n",
    "        if \"Part_Number\" in onhand.columns:\n",
    "            onhand = onhand.rename(columns={\"Part_Number\":\"Item\"})\n",
    "        onhand[\"Item\"] = onhand[\"Item\"].astype(str).str.strip()\n",
    "        onhand[\"On Hand\"] = pd.to_numeric(onhand[\"On Hand\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "        if \"Inventory Site\" not in onhand.columns:\n",
    "            onhand[\"Inventory Site\"] = site_filter  # broadcast INV to this site\n",
    "\n",
    "        onhand = onhand[[\"Inventory Site\",\"Item\",\"On Hand\"]]\n",
    "        # limit to items present in timeline to avoid bloat\n",
    "        if not timeline.empty:\n",
    "            onhand = onhand.merge(pairs, on=[\"Inventory Site\",\"Item\"], how=\"inner\")\n",
    "\n",
    "        timeline = timeline.merge(onhand, on=[\"Inventory Site\",\"Item\"], how=\"left\")\n",
    "        timeline[\"On Hand\"] = timeline[\"On Hand\"].fillna(0.0)\n",
    "    else:\n",
    "        timeline[\"On Hand\"] = 0.0\n",
    "\n",
    "    # running balance\n",
    "    if not timeline.empty:\n",
    "        timeline.sort_values([\"Inventory Site\",\"Item\",\"Ship Date\"], inplace=True)\n",
    "        cum_net = timeline.groupby([\"Inventory Site\",\"Item\"])[\"Net Movement\"].cumsum()\n",
    "        init_onhand = timeline.groupby([\"Inventory Site\",\"Item\"])[\"On Hand\"].transform(\"first\")\n",
    "        timeline[\"Projected Qty\"] = init_onhand + cum_net\n",
    "    else:\n",
    "        timeline[\"Projected Qty\"] = pd.Series(dtype=float)\n",
    "\n",
    "    return events, timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "847e7a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Ship Date  On Hand  Net Movement  Projected Qty\n",
      "2759 2025-10-09      9.0           0.0            9.0\n",
      "2760 2025-10-10      9.0           0.0            9.0\n",
      "2761 2025-10-11      9.0           0.0            9.0\n",
      "2762 2025-10-12      9.0           0.0            9.0\n",
      "2763 2025-10-13      9.0           0.0            9.0\n",
      "2764 2025-10-14      9.0           0.0            9.0\n",
      "2765 2025-10-15      9.0           0.0            9.0\n",
      "2766 2025-10-16      9.0           0.0            9.0\n",
      "2767 2025-10-17      9.0           0.0            9.0\n",
      "2768 2025-10-18      9.0           0.0            9.0\n",
      "2769 2025-10-19      9.0           0.0            9.0\n",
      "2770 2025-10-20      9.0           0.0            9.0\n",
      "2771 2025-10-21      9.0           0.0            9.0\n",
      "2772 2025-10-22      9.0           0.0            9.0\n",
      "2773 2025-10-23      9.0           0.0            9.0\n",
      "2774 2025-10-24      9.0           0.0            9.0\n",
      "2775 2025-10-25      9.0           0.0            9.0\n",
      "2776 2025-10-26      9.0           0.0            9.0\n",
      "2777 2025-10-27      9.0           0.0            9.0\n",
      "2778 2025-10-28      9.0           0.0            9.0\n",
      "2779 2025-10-29      9.0           0.0            9.0\n",
      "2780 2025-10-30      9.0           0.0            9.0\n",
      "2781 2025-10-31      9.0           0.0            9.0\n",
      "2782 2025-11-01      9.0           0.0            9.0\n",
      "2783 2025-11-02      9.0           0.0            9.0\n"
     ]
    }
   ],
   "source": [
    "# Prepare INV (no site column in your screenshot)\n",
    "initial_onhand_df = INV[[\"Part_Number\",\"On Hand\"]].copy()\n",
    "\n",
    "events, timeline = build_timephased_qty(\n",
    "    start_date=date.today(),\n",
    "    end_date=None,\n",
    "    freq=\"D\",\n",
    "    initial_onhand_df=initial_onhand_df,\n",
    "    site_filter=\"WH01S-NTA\",\n",
    ")\n",
    "\n",
    "part_view = timeline[\n",
    "    (timeline[\"Item\"] == \"TB-10\") & (timeline[\"Inventory Site\"] == \"WH01S-NTA\")\n",
    "]\n",
    "print(part_view[[\"Ship Date\",\"On Hand\",\"Net Movement\",\"Projected Qty\"]].head(25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
